{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cunhamaicon/petr4/blob/master/petr4_rnn3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9FmHJN-4EGB3"
   },
   "source": [
    "###Importação dos pacotes ncessários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ouLu3_HiDkYV",
    "outputId": "679e6934-f84a-421e-cabe-30b19ed8c220"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.models import model_from_json\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNÇÕES\n",
    "\n",
    "#Filtro\n",
    "def binario(valor):\n",
    "    bi=[]\n",
    "    for c in range(1,len(valor)):\n",
    "        if valor[c]>valor[c-1]:\n",
    "            bi.append(1)\n",
    "        elif valor[c]<valor[c-1]:\n",
    "            bi.append(0)\n",
    "        elif valor[c]==valor[c-1]:\n",
    "            bi.append(0.5)\n",
    "    return bi\n",
    "\n",
    "def filtro(real,predito):   \n",
    "    d=[]\n",
    "    g=0\n",
    "    for c in range(0,len(predito)):\n",
    "        if predito[c]==-1 or real[c]==-1:\n",
    "            d.append(c-g)\n",
    "            g+=1\n",
    "    for c in range(0,len(d)):\n",
    "        del(real[d[c]])\n",
    "        del(predito[d[c]])\n",
    "            \n",
    "    return real,predito\n",
    "\n",
    "#FORMATAÇÃO DOS DADOS\n",
    "def fit_dados(dados,dados_ptreino):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(tick_treino,dados_ptreino):\n",
    "        X_train.append(dados[i-tick_treino:i])\n",
    "        y_train.append(dados[i,coluna_fechamento])\n",
    "\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_train = np.reshape(X_train, (dados_ptreino-tick_treino,tick_treino,n_entradas))\n",
    "    \n",
    "    return X_train,y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vrqcVD6IA5I-"
   },
   "source": [
    "###Definição de parâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ori7cG6gAq__"
   },
   "outputs": [],
   "source": [
    "new_model=1\n",
    "#-----//////---------/////---------\n",
    "nome_model=\"EP=85_Train=700_Func=tahn_train_gradiente=300_tickTrei=16_time=15 min.json_fDropout_line.json\"\n",
    "nome_peso=\"EP=85_Train=700_Func=tahn_train_gradiente=300_tickTrei=16_time=15 min.json_fDropout_line.h5\"\n",
    "#-----//////---------/////---------\n",
    "epocas=50\n",
    "func=\"linear\"\n",
    "train_gradiente=16\n",
    "dados_ptreino=2000\n",
    "dados_ptest=500\n",
    "tick_treino=90\n",
    "div_dataset=70\n",
    "\n",
    "entradas=[0,1,2,3]\n",
    "n_entradas=len(entradas)\n",
    "coluna_fechamento=3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_kaesWlyEphm"
   },
   "source": [
    "###Criando os bancos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ImZTwErJEcCu"
   },
   "outputs": [],
   "source": [
    "detalhamento=\"n_epocas= {}; dados_treinados={}; train_gradiente={}; time=5 min; func={};sem_Dropout\".format(epocas,dados_ptreino,train_gradiente,tick_treino,func)\n",
    "\n",
    "dataset = pd.read_csv(os.path.join('GBPCHF',r\"C:\\Users\\edno2\\Desktop\\Rede_Binária\\GBPCHF_2020_05.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7du5bxSTFKGa"
   },
   "source": [
    "### Treinamento e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "br1VQlO57Lm8"
   },
   "source": [
    "Separando dois bancos, um de treinamento e um de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plJPYtrdFNtq",
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      ABERTURA   MAXIMA   MINIMA  FECHAMENTO\n",
       "0      1.20964  1.20982  1.20959     1.20961\n",
       "1      1.20961  1.20971  1.20956     1.20961\n",
       "2      1.20961  1.21007  1.20958     1.20982\n",
       "3      1.20980  1.20992  1.20980     1.20988\n",
       "4      1.20987  1.21003  1.20977     1.21001\n",
       "...        ...      ...      ...         ...\n",
       "3004   1.20698  1.20698  1.20683     1.20691\n",
       "3005   1.20692  1.20707  1.20692     1.20707\n",
       "3006   1.20708  1.20721  1.20687     1.20695\n",
       "3007   1.20696  1.20697  1.20675     1.20675\n",
       "3008   1.20675  1.20687  1.20665     1.20665\n",
       "\n",
       "[3009 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABERTURA</th>\n      <th>MAXIMA</th>\n      <th>MINIMA</th>\n      <th>FECHAMENTO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.20964</td>\n      <td>1.20982</td>\n      <td>1.20959</td>\n      <td>1.20961</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.20961</td>\n      <td>1.20971</td>\n      <td>1.20956</td>\n      <td>1.20961</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.20961</td>\n      <td>1.21007</td>\n      <td>1.20958</td>\n      <td>1.20982</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.20980</td>\n      <td>1.20992</td>\n      <td>1.20980</td>\n      <td>1.20988</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.20987</td>\n      <td>1.21003</td>\n      <td>1.20977</td>\n      <td>1.21001</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3004</th>\n      <td>1.20698</td>\n      <td>1.20698</td>\n      <td>1.20683</td>\n      <td>1.20691</td>\n    </tr>\n    <tr>\n      <th>3005</th>\n      <td>1.20692</td>\n      <td>1.20707</td>\n      <td>1.20692</td>\n      <td>1.20707</td>\n    </tr>\n    <tr>\n      <th>3006</th>\n      <td>1.20708</td>\n      <td>1.20721</td>\n      <td>1.20687</td>\n      <td>1.20695</td>\n    </tr>\n    <tr>\n      <th>3007</th>\n      <td>1.20696</td>\n      <td>1.20697</td>\n      <td>1.20675</td>\n      <td>1.20675</td>\n    </tr>\n    <tr>\n      <th>3008</th>\n      <td>1.20675</td>\n      <td>1.20687</td>\n      <td>1.20665</td>\n      <td>1.20665</td>\n    </tr>\n  </tbody>\n</table>\n<p>3009 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "pocent_treino=(len(dataset)//100)*div_dataset\n",
    "pocent_test=len(dataset)-pocent_treino\n",
    "\n",
    "\n",
    "dataset_train = dataset.iloc[:pocent_treino,1:]\n",
    "training_set = dataset_train.iloc[len(dataset_train)-dados_ptreino:].values.astype(float)\n",
    "\n",
    "dataset_test = dataset.iloc[pocent_treino:,1:]\n",
    "test_set = dataset_test.iloc[0:dados_ptest].values.astype(float)\n",
    "\n",
    "dataset_train.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feo_aHH4Fv-0"
   },
   "outputs": [],
   "source": [
    "#Fazendo a transformação dos dados para ficar no intervalo [0,1]\n",
    "\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "real_stock_price = sc.fit_transform(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRp_grOQ7rHE"
   },
   "source": [
    "Cada ciclo de treinamento deve ter o tamanho \"size\" definido anteriormente representando as \"size\" entradas anterioes. O conjunto de treinamento \"X_train\" deve emparelhar todas essas entradas. \"y_train\" é a saída da rede, o próximo elemento depois das \"size\" entradas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMATANDO OS DADOS \n",
    "\n",
    "X_train,y_train=fit_dados(training_set_scaled,dados_ptreino)\n",
    "\n",
    "X_test,real_preco=fit_dados(real_stock_price,dados_ptest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p8pcblfJGacd"
   },
   "source": [
    "## Construindo a RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WUmZPeb2GdVi"
   },
   "outputs": [],
   "source": [
    "def regressor():\n",
    "  regressor = Sequential()\n",
    "\n",
    "  regressor.add(LSTM(units = 33,activation=func,  return_sequences = True, kernel_regularizer = regularizers.l2(), input_shape = (tick_treino, n_entradas)))\n",
    "  #regressor.add(Dropout(0.2))\n",
    "\n",
    "  \n",
    "  regressor.add(LSTM(units = 33,return_sequences = True, kernel_regularizer = regularizers.l2 (0.0001)))\n",
    " \n",
    "  \n",
    "  regressor.add(LSTM(units = 33, return_sequences = True))\n",
    " \n",
    "\n",
    "  regressor.add(LSTM(units = 33))\n",
    " \n",
    "\n",
    "  regressor.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    " \n",
    "  regressor.compile(optimizer = \"adam\", loss = 'mean_squared_error')\n",
    "  \n",
    "  return regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w7AXjm7e9Ltf"
   },
   "source": [
    "Mostrando as informações da rede:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "colab_type": "code",
    "id": "1Hi86hA1G71v",
    "outputId": "54d3be1c-9d7a-426c-ffdb-3bcab175e7c9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 90, 33)            5016      \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 90, 33)            8844      \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 90, 33)            8844      \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 33)                8844      \n_________________________________________________________________\ndense (Dense)                (None, 1)                 34        \n=================================================================\nTotal params: 31,582\nTrainable params: 31,582\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "regressor = regressor()\n",
    "print(regressor.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WG2m0tyEWMR3"
   },
   "source": [
    "### Treinando a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = regressor.fit(X_train, y_train, epochs = epocas, batch_size =train_gradiente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "regressor_json = regressor.to_json()\n",
    "with open(\"ABERTURA_BINARIO_INDICADORES(MACD,STOC,BI)_100EPOCAS_LINEAR_24TICKS.json\", \"w\") as json_file:\n",
    "    json_file.write(regressor_json)\n",
    "# serialize weights to HDF5\n",
    "regressor.save_weights(\"ABERTURA_BINARIO_INDICADORES(MACD,STOC,BI)_100EPOCAS_LINEAR_24TICKS.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_model==1:\n",
    "    predicted_stock_price = regressor.predict(X_test) \n",
    "     \n",
    "\n",
    "if new_model==0:\n",
    "    # load json and create model\n",
    "    json_file = open(nome_model, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(nome_peso)\n",
    "    print(\"Loaded model from disk\")\n",
    "    \n",
    "    predicted_stock_price = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZC6MjemTWTFv"
   },
   "source": [
    "## Visualização dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1r2T9wSTkTk"
   },
   "outputs": [],
   "source": [
    "if new_model==1:\n",
    "    predicted_stock_price = regressor.predict(X_test) \n",
    "\n",
    "if new_model==0:\n",
    "    # load json and create model\n",
    "    json_file = open(nome_model, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(nome_peso)\n",
    "    print(\"Loaded model from disk\")\n",
    "    \n",
    "    predicted_stock_price = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TRANSFORMANDO EM BINARIO\n",
    "\n",
    "x2=binario(predicted_stock_price)\n",
    "x1=binario(real_preco)\n",
    "real,predito=filtro(x1,x2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-0834fed9d6d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#tp e tn são os corretos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredito\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0macuracia\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"n-----------------------Verdadeiro Positivo:{}\\nVerdadeiro Negativo:{}\\n-----------------------\\nFalso Positivo:{}\\nFalso Negativo:{}\\n-----------------------\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Acurracia:{:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macuracia\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \"\"\"\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 91\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "#tp e tn são os corretos\n",
    "tn, fp, fn, tp=confusion_matrix(real,predito).ravel()\n",
    "acuracia=((tp+tn)/(tp+tn+fp+fn))*100\n",
    "print(\"n-----------------------Verdadeiro Positivo:{}\\nVerdadeiro Negativo:{}\\n-----------------------\\nFalso Positivo:{}\\nFalso Negativo:{}\\n-----------------------\".format(tp,tn,fp,fn))\n",
    "print(\"Acurracia:{:.2f}\".format(acuracia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "petr4_rnn3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "b790771c7be7da65445b4075123aa246c39b686b2a3ea235f7d16c0f8601114c"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}